### This paper is accepted at CAI 2025 (in May) and will be published on IEEE Xplore. 

Paper Name: Enhancing Retrieval-Augmented Language Models
with Temporal Awareness

Abstract: Abstract—In this paper, we propose and evaluate TempRALM,
a temporally aware retrieval-augmented language model with
few-shot learning capabilities, which considers both the semantic
and temporal relevance of retrieved documents in relation to a
given query, rather than relying on semantic similarity alone.
Our approach demonstrates up to 74% improvement in performance
over the baseline ATLAS model(Adaptive Transformerbased
Large-scale Assistant) – a retrieval-augmented language
model, and 32% improvement over a state-of-the-art commercial
LLM(Large Language Models) augmented with retrieval. In
addition, we introduce and evaluate a novel automated method
for generating ground truth data for RALMs and temporal
question-answering, called Tablepedia, without requiring model
pre-training, document index replacement, or other computationally
intensive operations.

Index Terms—Information Retrieval, Temporality, Retrieval
Augmented Language Models
